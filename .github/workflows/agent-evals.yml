name: Agent Evaluations (Post-Deploy)

on:
  # Run after successful Vercel deployment (informational only)
  deployment_status:
  
  # Manual trigger for testing
  workflow_dispatch:
    inputs:
      base_url:
        description: 'Base URL to test (leave empty for production)'
        required: false
        default: ''
        type: string
      
  # Scheduled: Daily at 8am UTC (5am Argentina)
  schedule:
    - cron: '0 8 * * *'

# NOTE: This workflow is informational only.
# It does NOT block PRs or merges.
# Use CI Tests workflow (ci-tests.yml) for required checks.

jobs:
  agent-evals:
    name: Run Agent Evaluations
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    # Only run on successful deployments or manual/scheduled triggers
    if: |
      github.event_name == 'workflow_dispatch' ||
      github.event_name == 'schedule' ||
      (github.event_name == 'deployment_status' && github.event.deployment_status.state == 'success')

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Determine Base URL
        id: url
        run: |
          if [ "${{ github.event_name }}" == "deployment_status" ]; then
            # Use the deployment URL from Vercel (preview or production)
            DEPLOY_URL="${{ github.event.deployment_status.target_url }}"
            echo "Using deployment URL: $DEPLOY_URL"
            echo "base_url=$DEPLOY_URL" >> $GITHUB_OUTPUT
          elif [ -n "${{ inputs.base_url }}" ]; then
            # Manual trigger with custom URL
            echo "Using manual URL: ${{ inputs.base_url }}"
            echo "base_url=${{ inputs.base_url }}" >> $GITHUB_OUTPUT
          else
            # Default to production
            echo "Using production URL"
            echo "base_url=https://tuqui.vercel.app" >> $GITHUB_OUTPUT
          fi

      - name: Wait for deployment to stabilize
        if: github.event_name == 'deployment_status'
        run: |
          echo "üïê Waiting 30s for deployment to stabilize..."
          sleep 30
          
          # Verify the deployment is reachable
          echo "üîç Checking deployment health..."
          HEALTH_URL="${{ steps.url.outputs.base_url }}/api/health"
          for i in {1..5}; do
            if curl -sf "$HEALTH_URL" > /dev/null 2>&1; then
              echo "‚úÖ Deployment is healthy"
              break
            fi
            echo "‚è≥ Attempt $i/5 - waiting 10s..."
            sleep 10
          done

      - name: Run Agent Evaluations
        id: evals
        run: |
          echo "üöÄ Running evals against: ${{ steps.url.outputs.base_url }}"
          npm run test:evals 2>&1 | tee eval-output.txt
        env:
          EVAL_BASE_URL: ${{ steps.url.outputs.base_url }}
          INTERNAL_TEST_KEY: ${{ secrets.INTERNAL_TEST_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          TEST_TENANT_ID: ${{ secrets.TEST_TENANT_ID }}
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        continue-on-error: true

      - name: Extract pass rate
        id: extract
        run: |
          # Try to extract pass rate from output
          PASS_RATE=$(grep -oP 'Pass Rate: \K[\d.]+' eval-output.txt 2>/dev/null || echo "")
          
          # If not found, try alternative format
          if [ -z "$PASS_RATE" ]; then
            PASS_RATE=$(grep -oP '\d+\.\d+(?=% pass)' eval-output.txt 2>/dev/null || echo "0")
          fi
          
          # Check for 404 errors (deployment not ready)
          NOT_FOUND_COUNT=$(grep -c "404" eval-output.txt 2>/dev/null || echo "0")
          
          echo "pass_rate=$PASS_RATE" >> $GITHUB_OUTPUT
          echo "not_found_count=$NOT_FOUND_COUNT" >> $GITHUB_OUTPUT
          echo "üìä Pass Rate: $PASS_RATE%"
          echo "üîç 404 Errors: $NOT_FOUND_COUNT"

      - name: Check for deployment issues
        if: steps.extract.outputs.not_found_count > 10
        run: |
          echo "‚ùå Too many 404 errors (${{ steps.extract.outputs.not_found_count }})"
          echo "This usually means the deployment URL is incorrect or not ready."
          echo ""
          echo "Deployment URL used: ${{ steps.url.outputs.base_url }}"
          echo ""
          echo "Please check:"
          echo "  1. Vercel deployment is complete"
          echo "  2. The API routes exist at the deployment"
          echo "  3. Environment variables are set in Vercel"
          exit 1

      - name: Check threshold
        run: |
          PASS_RATE="${{ steps.extract.outputs.pass_rate }}"
          THRESHOLD=80
          
          if [ -z "$PASS_RATE" ] || [ "$PASS_RATE" == "0" ]; then
            echo "‚ùå Could not determine pass rate from eval output"
            cat eval-output.txt | tail -50
            exit 1
          fi
          
          if (( $(echo "$PASS_RATE < $THRESHOLD" | bc -l) )); then
            echo "‚ùå Pass rate ($PASS_RATE%) is below threshold ($THRESHOLD%)"
            exit 1
          else
            echo "‚úÖ Pass rate ($PASS_RATE%) meets threshold ($THRESHOLD%)"
          fi

      - name: Upload eval results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: eval-results-${{ github.run_id }}
          path: eval-output.txt
          retention-days: 30

      - name: Comment on PR (if applicable)
        if: |
          always() && 
          github.event_name == 'deployment_status' && 
          github.event.deployment.environment == 'preview'
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            const passRate = '${{ steps.extract.outputs.pass_rate }}' || '0';
            const notFoundCount = '${{ steps.extract.outputs.not_found_count }}' || '0';
            const deployUrl = '${{ steps.url.outputs.base_url }}';
            
            let status, message;
            
            if (parseInt(notFoundCount) > 10) {
              status = '‚ö†Ô∏è';
              message = `Deployment issues detected (${notFoundCount} 404 errors)`;
            } else if (parseFloat(passRate) >= 80) {
              status = '‚úÖ';
              message = `Pass Rate: ${passRate}%`;
            } else {
              status = '‚ùå';
              message = `Pass Rate: ${passRate}% (below 80% threshold)`;
            }
            
            // Find PR number from deployment
            const prs = await github.rest.pulls.list({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              head: `${context.repo.owner}:${context.payload.deployment.ref}`
            });
            
            if (prs.data.length > 0) {
              const prNumber = prs.data[0].number;
              
              await github.rest.issues.createComment({
                issue_number: prNumber,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: `## ü§ñ Agent Evaluation Results\n\n${status} **${message}**\n\nüîó Tested: ${deployUrl}\n\nSee [workflow run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) for details.`
              });
            }
